import pandas as pd
import os
import numpy as np
import streamlit as st
import plotly.graph_objects as go
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

def run(input_path, output_dir):
Â  Â  # ============================
Â  Â  # 1. Load data
Â  Â  # ============================
Â  Â  if not os.path.exists(input_path):
Â  Â  Â  Â  raise FileNotFoundError("File input tidak ditemukan")
Â  Â Â 
Â  Â  df = pd.read_excel(input_path)
Â  Â Â 
Â  Â  # Validasi Kolom
Â  Â  required_cols = {"opinion_context", "label_text"}
Â  Â  if not required_cols.issubset(df.columns):
Â  Â  Â  Â  if "processed_opinion" in df.columns:
Â  Â  Â  Â  Â  Â  st.warning("âš ï¸ Menggunakan 'processed_opinion'.")
Â  Â  Â  Â  Â  Â  df["feature_text"] = df["processed_opinion"]
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  raise ValueError("Kolom opinion_context tidak ditemukan!")
Â  Â  else:
Â  Â  Â  Â  df["feature_text"] = df["opinion_context"]

Â  Â  # Cleaning Simple
Â  Â  df = df.dropna(subset=["feature_text", "label_text"])
Â  Â  df["label_text"] = df["label_text"].str.lower().str.strip()
Â  Â  df = df[df["label_text"].isin(["positive", "negative"])]
Â  Â  df = df[df["feature_text"].astype(str).str.strip() != ""]
Â  Â Â 
Â  Â  if df.empty: return create_dummy_result()

Â  Â  # Cek jumlah kelas
Â  Â  if len(df["label_text"].unique()) < 2:
Â  Â  Â  Â  return create_dummy_result(accuracy=1.0)

Â  Â  # ============================
Â  Â  # 2. TF-IDF (KUNCI PERBAIKAN DISINI)
Â  Â  # ============================
Â  Â  X = df["feature_text"].astype(str)
Â  Â  y = df["label_text"]
Â  Â Â 
Â  Â  tfidf = TfidfVectorizer(
Â  Â  Â  Â  ngram_range=(1, 3),Â  Â # UBAH KE (1,3): Tangkap "not bad at all"
Â  Â  Â  Â  max_df=0.90,Â  Â  Â  Â  Â  # Abaikan kata yang muncul di 90% dokumen
Â  Â  Â  Â  min_df=2,Â  Â  Â  Â  Â  Â  Â # Abaikan typo unik
Â  Â  Â  Â  stop_words=None,Â  Â  Â  # JANGAN PAKAI "english". "No/Not" itu penting!
Â  Â  Â  Â  sublinear_tf=TrueÂ  Â  Â # Memuluskan frekuensi kata yang meledak
Â  Â  )
Â  Â Â 
Â  Â  X_tfidf = tfidf.fit_transform(X)
Â  Â Â 
Â  Â  # ============================
Â  Â  # 3. Split & Train
Â  Â  # ============================
Â  Â  try:
Â  Â  Â  Â  X_train, X_test, y_train, y_test = train_test_split(
Â  Â  Â  Â  Â  Â  X_tfidf, y, test_size=0.2, random_state=42, stratify=y
Â  Â  Â  Â  )
Â  Â  except ValueError:
Â  Â  Â  Â  X_train, X_test, y_train, y_test = train_test_split(
Â  Â  Â  Â  Â  Â  X_tfidf, y, test_size=0.2, random_state=42
Â  Â  Â  Â  )
Â  Â Â 
Â  Â  # Model Configuration
Â  Â  model = LogisticRegression(
Â  Â  Â  Â  max_iter=3000,
Â  Â  Â  Â  class_weight="balanced", # Tetap pakai balanced agar recall seimbang
Â  Â  Â  Â  solver="lbfgs",
Â  Â  Â  Â  C=2.0,Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Naikkan C sedikit (Model lebih percaya pada kata-kata spesifik)
Â  Â  Â  Â  random_state=42
Â  Â  )
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  model.fit(X_train, y_train)
Â  Â  Â  Â  y_pred = model.predict(X_test)
Â  Â  Â  Â Â 
Â  Â  Â  Â  results = {
Â  Â  Â  Â  Â  Â  "accuracy": accuracy_score(y_test, y_pred),
Â  Â  Â  Â  Â  Â  "classification_report": classification_report(
Â  Â  Â  Â  Â  Â  Â  Â  y_test, y_pred, output_dict=True, zero_division=0
Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  "confusion_matrix": confusion_matrix(y_test, y_pred, labels=["negative", "positive"])
Â  Â  Â  Â  }

Â  Â  Â  Â  # Analisis Fitur (Cek kata apa yang bikin error)
Â  Â  Â  Â  feature_names = tfidf.get_feature_names_out()
Â  Â  Â  Â  coefs = model.coef_[0]
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Ambil Top 10 Positive & Negative words
Â  Â  Â  Â  top_pos = sorted(zip(feature_names, coefs), key=lambda x: x[1], reverse=True)[:10]
Â  Â  Â  Â  top_neg = sorted(zip(feature_names, coefs), key=lambda x: x[1])[:10]
Â  Â  Â  Â Â 
Â  Â  Â  Â  results["top_features"] = {"positive": top_pos, "negative": top_neg}

Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error: {str(e)}")
Â  Â  Â  Â  return create_dummy_result()
Â  Â Â 
Â  Â  display_results(results, y_test, y_pred)
Â  Â  return results

# --- HELPER VISUALISASI ---
def create_dummy_result(accuracy=0.0):
Â  Â  return {
Â  Â  Â  Â  "accuracy": accuracy,
Â  Â  Â  Â  "classification_report": {
Â  Â  Â  Â  Â  Â  "weighted avg": {"precision": 0, "recall": 0, "f1-score": 0},
Â  Â  Â  Â  Â  Â  "positive": {"precision": 0, "recall": 0, "f1-score": 0},
Â  Â  Â  Â  Â  Â  "negative": {"precision": 0, "recall": 0, "f1-score": 0}
Â  Â  Â  Â  },
Â  Â  Â  Â  "confusion_matrix": np.array([[0, 0], [0, 0]])
Â  Â  }

def display_results(results, y_test, y_pred):
Â  Â  st.markdown("---")
Â  Â  st.markdown("### ğŸ“Š Model Performance (Improved)")
Â  Â  col1, col2, col3, col4 = st.columns(4)
Â  Â  report = results["classification_report"]
Â  Â Â 
Â  Â  acc = results.get('accuracy', 0)
Â  Â  col1.metric("Accuracy", f"{acc:.2%}")
Â  Â  col2.metric("Precision", f"{report['weighted avg']['precision']:.2%}")
Â  Â  col3.metric("Recall", f"{report['weighted avg']['recall']:.2%}")
Â  Â  col4.metric("F1-Score", f"{report['weighted avg']['f1-score']:.2%}")
Â  Â Â 
Â  Â  st.markdown("---")
Â  Â  c1, c2 = st.columns(2)
Â  Â  with c1:
Â  Â  Â  Â  st.markdown("#### ğŸ¯ Confusion Matrix")
Â  Â  Â  Â  plot_confusion_matrix_elegant(results["confusion_matrix"])
Â  Â  with c2:
Â  Â  Â  Â  st.markdown("#### ğŸ“ˆ Class Performance")
Â  Â  Â  Â  plot_class_metrics_elegant(report)
Â  Â  Â  Â Â 
Â  Â  if "top_features" in results:
Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  st.markdown("### ğŸ” Kata Penentu Keputusan")
Â  Â  Â  Â  cp, cn = st.columns(2)
Â  Â  Â  Â  with cp:
Â  Â  Â  Â  Â  Â  st.success("**Top Positive Words:**")
Â  Â  Â  Â  Â  Â  st.write(", ".join([f"{w} ({c:.2f})" for w, c in results["top_features"]["positive"]]))
Â  Â  Â  Â  with cn:
Â  Â  Â  Â  Â  Â  st.error("**Top Negative Words:**")
Â  Â  Â  Â  Â  Â  st.write(", ".join([f"{w} ({c:.2f})" for w, c in results["top_features"]["negative"]]))

def plot_confusion_matrix_elegant(cm):
Â  Â  labels = ['Negative', 'Positive'] # Pastikan urutan label sesuai model
Â  Â  cm_sum = cm.sum(axis=1)[:, None]
Â  Â  cm_p = np.divide(cm.astype('float'), cm_sum, out=np.zeros_like(cm.astype('float')), where=cm_sum!=0) * 100
Â  Â Â 
Â  Â  text = [[f"{cm[i][j]}<br>({cm_p[i][j]:.1f}%)" for j in range(len(cm[i]))] for i in range(len(cm))]
Â  Â Â 
Â  Â  fig = go.Figure(data=go.Heatmap(
Â  Â  Â  Â  z=cm, x=labels, y=labels, text=text,
Â  Â  Â  Â  texttemplate="%{text}", textfont={"size": 14, "color": "white"},
Â  Â  Â  Â  colorscale=[[0, '#3D5A80'], [0.5, '#98C1D9'], [1, '#EE6C4D']], showscale=False
Â  Â  ))
Â  Â  fig.update_layout(height=300, margin=dict(l=20,r=20,t=20,b=20), plot_bgcolor='rgba(0,0,0,0)')
Â  Â  st.plotly_chart(fig, use_container_width=True)

def plot_class_metrics_elegant(report):
Â  Â  classes = [c for c in ['negative', 'positive'] if c in report]
Â  Â  metrics = ['precision', 'recall', 'f1-score']
Â  Â  data = []
Â  Â  colors = ['#3D5A80', '#98C1D9', '#EE6C4D']
Â  Â  for i, metric in enumerate(metrics):
Â  Â  Â  Â  vals = [report[cls][metric] for cls in classes]
Â  Â  Â  Â  data.append(go.Bar(name=metric.capitalize(), x=[c.capitalize() for c in classes], y=vals, text=[f'{v:.2%}' for v in vals], textposition='auto', marker_color=colors[i]))
Â  Â Â 
Â  Â  fig = go.Figure(data=data)
Â  Â  fig.update_layout(barmode='group', height=300, margin=dict(l=20,r=20,t=20,b=20), plot_bgcolor='rgba(0,0,0,0)', legend=dict(orientation="h", y=1.1))
Â  Â  st.plotly_chart(fig, use_container_width=True)
